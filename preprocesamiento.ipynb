{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d39827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-Tumor Free: 935\n",
      "WT-With Tumor: 125\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Carga del JSON clínico\n",
    "with open(\"data/clinical.project-tcga-brca.2025-06-30.json\", \"r\") as f:\n",
    "    clinical_data = json.load(f)\n",
    "\n",
    "# 2. Función para obtener el disease_response relevante por caso\n",
    "def get_primary_response(follow_ups):\n",
    "    # Buscar la entrada “Last Contact”\n",
    "    last_contacts = [fu for fu in follow_ups\n",
    "                     if fu.get(\"timepoint_category\") == \"Last Contact\"]\n",
    "    if last_contacts:\n",
    "        resp = last_contacts[0].get(\"disease_response\")\n",
    "        # Si Last Contact tiene respuesta y no es \"Unknown\", devuélvela\n",
    "        if resp and resp.lower() != \"unknown\":\n",
    "            return resp\n",
    "    # Si no hay Last Contact o su respuesta es \"Unknown\", buscar el siguiente Follow‑up\n",
    "    for fu in follow_ups:\n",
    "        if fu.get(\"timepoint_category\") != \"Last Contact\":\n",
    "            resp = fu.get(\"disease_response\")\n",
    "            if resp and resp.lower() != \"unknown\":\n",
    "                return resp\n",
    "    # Si no se encuentra ninguna respuesta válida\n",
    "    return None\n",
    "\n",
    "# 3. Recoger todas las respuestas “primarias”\n",
    "primary_responses = []\n",
    "for case in clinical_data:\n",
    "    follow_ups = case.get(\"follow_ups\", [])\n",
    "    resp = get_primary_response(follow_ups)\n",
    "    if resp:\n",
    "        primary_responses.append(resp)\n",
    "\n",
    "# 4. Contar ocurrencias de cada respuesta\n",
    "counts = Counter(primary_responses)\n",
    "\n",
    "# 5. Mostrar resultados\n",
    "for response, count in counts.most_common():\n",
    "    print(f\"{response}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6e0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras de tumor primario encontradas: 385\n",
      "  submitter_id.samples response_group\n",
      "0     TCGA-3C-AAAU-01A              1\n",
      "1     TCGA-3C-AALI-01A              0\n",
      "2     TCGA-3C-AALJ-01A              0\n",
      "3     TCGA-3C-AALK-01A              0\n",
      "4     TCGA-4H-AAAK-01A              0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Carga del archivo de etiquetas\n",
    "# Ajusta la ruta y el separador ('\\t' si es tabulado)\n",
    "df = pd.read_csv(\"data/TCGA-BRCA-binary-labels.txt\", \n",
    "                 sep=\"\\t\", \n",
    "                 header=None, \n",
    "                 names=[\"index\", \"submitter_id.samples\", \"response_group\"],\n",
    "                 dtype={\"submitter_id.samples\": str})\n",
    "\n",
    "# 2. Filtrar solo barcodes que terminen en -01A, -01B, -01C, etc.\n",
    "mask = df[\"submitter_id.samples\"].str.contains(r\"-01[A-Z]$\", na=False)\n",
    "df_tumor_primary = df[mask].copy()\n",
    "\n",
    "# 3. (Opcional) Resetear índice y descartar la columna 'index'\n",
    "df_tumor_primary.reset_index(drop=True, inplace=True)\n",
    "df_tumor_primary = df_tumor_primary.drop(columns=[\"index\"])\n",
    "\n",
    "# 4. Guardar resultado\n",
    "df_tumor_primary.to_csv(\"data/TCGA-BRCA-binary-labels-clean.txt\", \n",
    "                        sep=\"\\t\", \n",
    "                        index=False)\n",
    "\n",
    "print(\"Muestras de tumor primario encontradas:\", len(df_tumor_primary))\n",
    "print(df_tumor_primary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8cb98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submitter_id.samples  recibio_quimio disease_response_final  \\\n",
      "0     TCGA-E2-A1IU-01A           False          TF-Tumor Free   \n",
      "1     TCGA-A1-A0SB-01A           False          TF-Tumor Free   \n",
      "2     TCGA-A2-A04W-01A            True          TF-Tumor Free   \n",
      "3     TCGA-AN-A0AM-01A           False          TF-Tumor Free   \n",
      "4     TCGA-LL-A440-01A           False          TF-Tumor Free   \n",
      "5     TCGA-A7-A26E-01A           False          TF-Tumor Free   \n",
      "6     TCGA-A8-A07W-01A            True          WT-With Tumor   \n",
      "7     TCGA-D8-A1XY-01A            True          TF-Tumor Free   \n",
      "8     TCGA-EW-A1P7-01A            True          WT-With Tumor   \n",
      "9     TCGA-AO-A128-01A            True          TF-Tumor Free   \n",
      "\n",
      "  clasificacion_interna  response_group  \n",
      "0           desconocido             NaN  \n",
      "1           desconocido             NaN  \n",
      "2                   pCR             NaN  \n",
      "3           desconocido             NaN  \n",
      "4           desconocido             0.0  \n",
      "5           desconocido             0.0  \n",
      "6                no_pCR             0.0  \n",
      "7                   pCR             0.0  \n",
      "8                no_pCR             1.0  \n",
      "9                   pCR             0.0  \n",
      "\n",
      "→ Conteo clasificaciones internas:\n",
      "clasificacion_interna\n",
      "desconocido    587\n",
      "pCR            486\n",
      "no_pCR          25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "→ Conteo etiquetas externas (response_group):\n",
      "response_group\n",
      "NaN    716\n",
      "0.0    342\n",
      "1.0     40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "→ Conteo quimioterapia recibida:\n",
      "recibio_quimio\n",
      "False    578\n",
      "True     520\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar JSON clínico\n",
    "with open(\"data/clinical.project-tcga-brca.2025-06-30.json\", \"r\") as f:\n",
    "    clinical_data = json.load(f)\n",
    "\n",
    "# 2. Función para extraer respuesta principal\n",
    "def get_primary_response(follow_ups):\n",
    "    for fu in follow_ups:\n",
    "        if fu.get(\"timepoint_category\") == \"Last Contact\" and fu.get(\"disease_response\"):\n",
    "            return fu[\"disease_response\"]\n",
    "    for fu in follow_ups:\n",
    "        resp = fu.get(\"disease_response\")\n",
    "        if resp and resp.lower() != \"unknown\":\n",
    "            return resp\n",
    "    return None\n",
    "\n",
    "# 3. Extraer datos clínicos\n",
    "def extract_info(caso):\n",
    "    sid = caso.get(\"submitter_id\")\n",
    "    sid_sample = f\"{sid}-01A\"  # ← Agrega sufijo -01A directamente\n",
    "    follow_ups = caso.get(\"follow_ups\", [])\n",
    "    diag = caso.get(\"diagnoses\", [{}])[0]\n",
    "    treatments = diag.get(\"treatments\", [])\n",
    "\n",
    "    # ¿Recibió quimioterapia?\n",
    "    recibio_quimio = any(\"Chemo\" in t.get(\"treatment_type\", \"\") for t in treatments)\n",
    "\n",
    "    # Respuesta clínica\n",
    "    final_resp = get_primary_response(follow_ups) or \"Unknown\"\n",
    "    rlow = final_resp.lower()\n",
    "\n",
    "    # Clasificación interna\n",
    "    if recibio_quimio:\n",
    "        if \"tumor free\" in rlow:\n",
    "            clas = \"pCR\"\n",
    "        elif rlow != \"unknown\":\n",
    "            clas = \"no_pCR\"\n",
    "        else:\n",
    "            clas = \"desconocido\"\n",
    "    else:\n",
    "        clas = \"desconocido\"\n",
    "\n",
    "    return {\n",
    "        \"submitter_id.samples\": sid_sample,\n",
    "        \"recibio_quimio\": recibio_quimio,\n",
    "        \"disease_response_final\": final_resp,\n",
    "        \"clasificacion_interna\": clas\n",
    "    }\n",
    "\n",
    "# 4. Convertir JSON a DataFrame\n",
    "df_clin = pd.DataFrame([extract_info(c) for c in clinical_data])\n",
    "\n",
    "# 5. Leer .txt de etiquetas binarios\n",
    "def load_labels(path):\n",
    "    rows = []\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            parts = line.strip().split()\n",
    "            if not parts or i == 0:\n",
    "                continue\n",
    "            barcode, label = parts[-2], parts[-1]\n",
    "            if label.isdigit():\n",
    "                rows.append({\"sample\": barcode, \"response_group\": int(label)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_labels = load_labels(\"data/TCGA-BRCA-binary-labels-clean.txt\")\n",
    "\n",
    "# 6. Filtrar solo muestras tumorales primarias -01A\n",
    "df_labels = df_labels[df_labels[\"sample\"].str.endswith(\"-01A\", na=False)].copy()\n",
    "df_labels.rename(columns={\"sample\": \"submitter_id.samples\"}, inplace=True)\n",
    "\n",
    "# 7. Hacer merge por barcode completo\n",
    "df_final = df_clin.merge(df_labels, on=\"submitter_id.samples\", how=\"left\")\n",
    "\n",
    "# 8. Guardar resultado\n",
    "df_final.to_csv(\"data/TCGA-BRCA-clinical-etiquetas-01A.csv\", index=False)\n",
    "\n",
    "# 9. Ver resumen\n",
    "print(df_final.head(10))\n",
    "print(\"\\n→ Conteo clasificaciones internas:\")\n",
    "print(df_final[\"clasificacion_interna\"].value_counts(dropna=False))\n",
    "print(\"\\n→ Conteo etiquetas externas (response_group):\")\n",
    "print(df_final[\"response_group\"].value_counts(dropna=False))\n",
    "print(\"\\n→ Conteo quimioterapia recibida:\")\n",
    "print(df_final[\"recibio_quimio\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fee931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respuesta_final\n",
      "NaN    538\n",
      "0.0    350\n",
      "1.0    210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivo con columnas ya procesadas\n",
    "df = pd.read_csv(\"data/TCGA-BRCA-clinical-etiquetas-01A.csv\")\n",
    "\n",
    "# Mapear clasificacion_interna a número para comparar con response_group\n",
    "mapa_clas = {\"pCR\": 1, \"no_pCR\": 0, \"desconocido\": None}\n",
    "\n",
    "def resolver_fila(row):\n",
    "    clas = mapa_clas.get(row[\"clasificacion_interna\"])\n",
    "    label = row[\"response_group\"]\n",
    "\n",
    "    # CASO 1: si son distintos y hay label → usar label\n",
    "    if pd.notna(label) and clas != label:\n",
    "        return label\n",
    "    # CASO 2: si clasificacion_interna es válida (no desconocido)\n",
    "    if clas is not None:\n",
    "        return clas\n",
    "    # Si no hay ninguna confiable\n",
    "    return None\n",
    "\n",
    "# Aplicar lógica\n",
    "df[\"respuesta_final\"] = df.apply(resolver_fila, axis=1)\n",
    "\n",
    "# Exportar archivos\n",
    "df.to_csv(\"data/BRCA_todo_combinado.csv\", index=False)\n",
    "\n",
    "# 3 subconjuntos:\n",
    "df[df[\"respuesta_final\"].isin([0,1])].to_csv(\"data/BRCA_finales_usables.csv\", index=False)\n",
    "df[df[\"respuesta_final\"].isna()].to_csv(\"data/BRCA_sin_respuesta_final.csv\", index=False)\n",
    "df[df[\"clasificacion_interna\"] == \"desconocido\"].to_csv(\"data/BRCA_con_desconocido_original.csv\", index=False)\n",
    "\n",
    "# Reporte\n",
    "print(df[\"respuesta_final\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5857287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se generaron los archivos:\n",
      "· diferencias_prioridad_clasificacion_interna.csv\n",
      "· diferencias_prioridad_response_group.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Carga del CSV principal (ajusta ruta si hace falta)\n",
    "df = pd.read_csv(\"data/TCGA-BRCA-clinical-etiquetas-01A.csv\")\n",
    "\n",
    "# 2. Mapear clasificacion_interna a valores numéricos para comparar\n",
    "map_clas = {\"pCR\": 1.0, \"no_pCR\": 0.0}\n",
    "df[\"clas_int_num\"] = df[\"clasificacion_interna\"].map(map_clas)\n",
    "\n",
    "# 3. Filtrado: clasificacion_interna válida y distinta de response_group\n",
    "mask = (\n",
    "    (df[\"clasificacion_interna\"] != \"desconocido\") &\n",
    "    (df[\"clas_int_num\"] != df[\"response_group\"])\n",
    ")\n",
    "df_diff = df[mask].copy()\n",
    "\n",
    "# 4. Versiones con distinta prioridad\n",
    "# 4.1 Prioridad a clasificacion_interna\n",
    "df_priority_clas = df_diff.copy()\n",
    "df_priority_clas[\"respuesta_final\"] = df_priority_clas[\"clas_int_num\"]\n",
    "\n",
    "# 4.2 Prioridad a response_group, rellenando NaN con clas_int_num\n",
    "df_priority_resp = df_diff.copy()\n",
    "df_priority_resp[\"respuesta_final\"] = df_priority_resp[\"response_group\"].fillna(df_priority_resp[\"clas_int_num\"])\n",
    "\n",
    "# 5. Guardar a CSV\n",
    "df_priority_clas.to_csv(\"data/diferencias_prioridad_clasificacion_interna.csv\", index=False)\n",
    "df_priority_resp.to_csv(\"data/diferencias_prioridad_response_group.csv\", index=False)\n",
    "\n",
    "print(\"Se generaron los archivos:\")\n",
    "print(\"· diferencias_prioridad_clasificacion_interna.csv\")\n",
    "print(\"· diferencias_prioridad_response_group.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afc5409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Carga de los CSV generados\n",
    "df_clas = pd.read_csv(\"data/diferencias_prioridad_clasificacion_interna.csv\")\n",
    "df_resp = pd.read_csv(\"data/diferencias_prioridad_response_group.csv\")\n",
    "\n",
    "# 2. Cómputo de distribuciones de 'respuesta_final'\n",
    "counts_clas = df_clas['respuesta_final'].value_counts().sort_index()\n",
    "counts_resp = df_resp['respuesta_final'].value_counts().sort_index()\n",
    "\n",
    "# 3. Conversión a proporciones\n",
    "props_clas = counts_clas / counts_clas.sum()\n",
    "props_resp = counts_resp / counts_resp.sum()\n",
    "\n",
    "# 4. DataFrame comparativo\n",
    "df_comp = pd.DataFrame({\n",
    "    'Prioridad Clas. Interna': props_clas,\n",
    "    'Prioridad Response Group': props_resp\n",
    "}).fillna(0)\n",
    "\n",
    "# 5. Gráfico de barras lado a lado\n",
    "labels = df_comp.index.tolist()\n",
    "x = range(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.bar([i - width/2 for i in x], df_comp['Prioridad Clas. Interna'], width, label='Prioridad .json')\n",
    "ax.bar([i + width/2 for i in x], df_comp['Prioridad Response Group'], width, label='Prioridad .txt')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlabel('respuesta_final')\n",
    "ax.set_ylabel('Proporción')\n",
    "ax.set_title('Comparación de distribuciones de respuesta_final')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3034f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Cargar matriz de expresión génica\n",
    "expr_path = \"data/TCGA.BRCA.sampleMap_HiSeqV2/HiSeqV2\"\n",
    "expr = pd.read_csv(expr_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "# Transponer: muestras como filas, genes como columnas\n",
    "expr = expr.T\n",
    "\n",
    "# limpieza\n",
    "expr.index = expr.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed1226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar etiquetas refinadas\n",
    "labels = pd.read_csv(\"data/diferencias_prioridad_response_group.csv\")\n",
    "\n",
    "# Estandarizar IDs base (sin sufijo A/B/C)\n",
    "labels[\"sample_id\"] = labels[\"submitter_id.samples\"].str[:-1]\n",
    "\n",
    "# Filtrar los válidos\n",
    "expr_filtered = expr.loc[expr.index.isin(labels[\"sample_id\"])]\n",
    "labels_filtered = labels[labels[\"sample_id\"].isin(expr_filtered.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85ea896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge usando sample_id\n",
    "merged = expr_filtered.merge(labels_filtered, left_index=True, right_on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71faf77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columnas meta que no son genes\n",
    "metadata_cols = [\n",
    "    \"submitter_id.samples\", \"recibio_quimio\", \"disease_response_final\",\n",
    "    \"clasificacion_interna\", \"response_group\", \"clas_int_num\",\n",
    "    \"respuesta_final\", \"sample_id\"\n",
    "]\n",
    "# Separar features y etiquetas\n",
    "X = merged.drop(columns=[c for c in metadata_cols if c in merged.columns])\n",
    "\n",
    "y = merged[\"respuesta_final\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffb604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Listo\n",
      "X shape: (498, 20530)\n",
      "y shape: (498,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guardar CSV con todo\n",
    "merged.to_csv(\"data/TCGA_BRCA_expression_with_labels.csv\", index=False)\n",
    "\n",
    "# Verificación\n",
    "print(\"✅ Listo\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f71bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar archivo CSV para test\n",
    "\n",
    "# Cargar etiquetas refinadas\n",
    "labels = pd.read_csv(\"data/BRCA_sin_respuesta_final.csv\")\n",
    "\n",
    "# Estandarizar IDs base (sin sufijo A/B/C)\n",
    "labels[\"sample_id\"] = labels[\"submitter_id.samples\"].str[:-1]\n",
    "\n",
    "# Filtrar los válidos\n",
    "expr_filtered = expr.loc[expr.index.isin(labels[\"sample_id\"])]\n",
    "labels_filtered = labels[labels[\"sample_id\"].isin(expr_filtered.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd10dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge usando sample_id\n",
    "merged = expr_filtered.merge(labels_filtered, left_index=True, right_on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e160d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columnas meta que no son genes\n",
    "metadata_cols = [\n",
    "    \"submitter_id.samples\", \"recibio_quimio\", \"disease_response_final\",\n",
    "    \"clasificacion_interna\", \"response_group\",\n",
    "    \"respuesta_final\", \"sample_id\"\n",
    "]\n",
    "# Separar features y etiquetas\n",
    "X_test = merged.drop(columns=[c for c in metadata_cols if c in merged.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a057a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Listo\n",
      "X shape: (537, 20530)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guardar CSV con todo\n",
    "merged.to_csv(\"data/TCGA_BRCA_expression_test.csv\", index=False)\n",
    "\n",
    "# Verificación\n",
    "print(\"✅ Listo\")\n",
    "print(\"X shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe370e4c",
   "metadata": {},
   "source": [
    "La **Desviación Absoluta Mediana (MAD)** de una variable $X$ se define como:\n",
    "\n",
    "$$\n",
    "\\mathrm{MAD}(X) = \\mathrm{median}\\bigl(\\,\\bigl|X_i - \\mathrm{median}(X)\\bigr|\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $\\mathrm{median}(X)$ es la mediana de todos los valores $X_i$.\n",
    "* $\\bigl|X_i - \\mathrm{median}(X)\\bigr|$ es la distancia absoluta de cada valor a la mediana.\n",
    "* A esa lista de distancias se le aplica de nuevo la mediana.\n",
    "\n",
    "MAD mide la dispersión de los datos usando distancias absolutas respecto al punto central (la mediana), siendo robusto ante valores extremos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745094d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de genes y escalado (top 20% MAD + Min–Max)\n",
    "medianas = X.median(axis=0)\n",
    "mad = ((X - medianas).abs()).median(axis=0)\n",
    "\n",
    "# Filtrar top 20% genes por MAD\n",
    "n_top = int(len(mad) * 0.2)\n",
    "top_genes = mad.sort_values(ascending=False).iloc[:n_top].index\n",
    "X_filt = X[top_genes]\n",
    "X_test_filt = X_test[top_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "881d8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 5. Normalización Min–Max\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_filt),\n",
    "    index=X_filt.index,\n",
    "    columns=X_filt.columns\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_test_filt),\n",
    "    index=X_test_filt.index,\n",
    "    columns=X_test_filt.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf3cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ MAD calculado y top20% genes seleccionados:\n",
      "Total genes: 20530\n",
      "Genes filtrados: 4106\n",
      "X_scaled shape: (498, 4106)\n",
      "y shape: (498,)\n"
     ]
    }
   ],
   "source": [
    "# 6. Guardar y verificar\n",
    "X_scaled.to_csv(\"data/X_scaled_top20pct_genes.csv\", index=True)\n",
    "X_test_scaled.to_csv(\"data/X_test_scaled_top20pct_genes.csv\", index=True)\n",
    "pd.Series(y.values, index=y.index).to_csv(\"data/y_labels.csv\", index=True)\n",
    "\n",
    "print(\"✔ MAD calculado y top20% genes seleccionados:\")\n",
    "print(\"Total genes:\", X.shape[1])\n",
    "print(\"Genes filtrados:\", X_filt.shape[1])\n",
    "print(\"X_scaled shape:\", X_scaled.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cfce3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc9b8000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1560.6985\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 2, Loss: 955.3658\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 3, Loss: 705.0226\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 4, Loss: 661.4224\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 5, Loss: 639.2854\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 6, Loss: 627.3900\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 7, Loss: 619.2450\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 8, Loss: 612.5062\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 9, Loss: 606.8982\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 10, Loss: 603.8154\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 11, Loss: 603.6565\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 12, Loss: 601.1523\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 13, Loss: 602.3343\n",
      "Epoch 14, Loss: 600.0927\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 15, Loss: 595.8199\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 16, Loss: 592.2662\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 17, Loss: 591.2115\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 18, Loss: 590.4286\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 19, Loss: 589.4651\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 20, Loss: 589.6853\n",
      "Epoch 21, Loss: 589.9934\n",
      "Epoch 22, Loss: 590.0770\n",
      "Epoch 23, Loss: 587.5781\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 24, Loss: 584.6087\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 25, Loss: 581.3873\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 26, Loss: 581.2964\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 27, Loss: 578.5885\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 28, Loss: 575.8448\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 29, Loss: 572.2314\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 30, Loss: 570.3346\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 31, Loss: 569.2529\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 32, Loss: 568.1222\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 33, Loss: 566.3942\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 34, Loss: 565.4680\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 35, Loss: 564.7877\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 36, Loss: 563.4560\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 37, Loss: 563.2537\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 38, Loss: 562.3950\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 39, Loss: 561.2302\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 40, Loss: 560.1722\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 41, Loss: 560.0521\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 42, Loss: 558.2601\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 43, Loss: 555.4964\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 44, Loss: 551.9195\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 45, Loss: 548.8037\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 46, Loss: 542.8448\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 47, Loss: 537.1751\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 48, Loss: 533.4854\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 49, Loss: 530.7525\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 50, Loss: 524.0556\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 51, Loss: 521.8315\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 52, Loss: 521.3966\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 53, Loss: 521.6745\n",
      "Epoch 54, Loss: 517.8069\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 55, Loss: 517.4090\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 56, Loss: 515.4551\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 57, Loss: 514.6077\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 58, Loss: 514.3194\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 59, Loss: 512.6867\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 60, Loss: 512.1644\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 61, Loss: 511.6271\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 62, Loss: 512.3016\n",
      "Epoch 63, Loss: 511.2506\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 64, Loss: 510.0274\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 65, Loss: 509.4674\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 66, Loss: 508.2365\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 67, Loss: 508.9278\n",
      "Epoch 68, Loss: 508.9830\n",
      "Epoch 69, Loss: 508.1073\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 70, Loss: 506.1043\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 71, Loss: 505.2641\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 72, Loss: 505.4088\n",
      "Epoch 73, Loss: 505.5224\n",
      "Epoch 74, Loss: 505.4523\n",
      "Epoch 75, Loss: 507.6022\n",
      "Epoch 76, Loss: 507.7763\n",
      "Epoch 77, Loss: 505.5504\n",
      "Epoch 78, Loss: 506.1951\n",
      "Epoch 79, Loss: 504.0258\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 80, Loss: 503.6172\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 81, Loss: 503.7777\n",
      "Epoch 82, Loss: 502.7693\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 83, Loss: 501.9301\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 84, Loss: 502.4015\n",
      "Epoch 85, Loss: 504.3232\n",
      "Epoch 86, Loss: 506.7452\n",
      "Epoch 87, Loss: 506.6643\n",
      "Epoch 88, Loss: 503.0959\n",
      "Epoch 89, Loss: 504.4997\n",
      "Epoch 90, Loss: 505.6836\n",
      "Epoch 91, Loss: 503.9817\n",
      "Epoch 92, Loss: 500.6932\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 93, Loss: 499.5534\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 94, Loss: 498.9924\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 95, Loss: 497.9462\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 96, Loss: 496.4802\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 97, Loss: 498.0897\n",
      "Epoch 98, Loss: 497.3841\n",
      "Epoch 99, Loss: 497.5113\n",
      "Epoch 100, Loss: 496.3441\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 101, Loss: 497.4276\n",
      "Epoch 102, Loss: 498.1650\n",
      "Epoch 103, Loss: 499.3058\n",
      "Epoch 104, Loss: 496.7400\n",
      "Epoch 105, Loss: 496.3783\n",
      "Epoch 106, Loss: 496.7168\n",
      "Epoch 107, Loss: 496.7141\n",
      "Epoch 108, Loss: 495.3369\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 109, Loss: 495.7319\n",
      "Epoch 110, Loss: 495.1781\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 111, Loss: 493.2290\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 112, Loss: 493.8567\n",
      "Epoch 113, Loss: 494.5592\n",
      "Epoch 114, Loss: 498.1535\n",
      "Epoch 115, Loss: 497.5278\n",
      "Epoch 116, Loss: 495.3557\n",
      "Epoch 117, Loss: 493.2146\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 118, Loss: 493.6573\n",
      "Epoch 119, Loss: 493.4165\n",
      "Epoch 120, Loss: 493.1610\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 121, Loss: 495.1610\n",
      "Epoch 122, Loss: 496.0652\n",
      "Epoch 123, Loss: 494.1003\n",
      "Epoch 124, Loss: 492.8287\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 125, Loss: 492.7367\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 126, Loss: 492.8277\n",
      "Epoch 127, Loss: 492.3799\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 128, Loss: 492.8058\n",
      "Epoch 129, Loss: 491.2182\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 130, Loss: 490.3996\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 131, Loss: 490.9730\n",
      "Epoch 132, Loss: 490.6296\n",
      "Epoch 133, Loss: 491.9143\n",
      "Epoch 134, Loss: 494.4216\n",
      "Epoch 135, Loss: 494.4543\n",
      "Epoch 136, Loss: 493.1181\n",
      "Epoch 137, Loss: 492.8250\n",
      "Epoch 138, Loss: 492.7578\n",
      "Epoch 139, Loss: 490.9363\n",
      "Epoch 140, Loss: 489.3016\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 141, Loss: 490.9986\n",
      "Epoch 142, Loss: 489.6275\n",
      "Epoch 143, Loss: 489.3906\n",
      "Epoch 144, Loss: 489.5123\n",
      "Epoch 145, Loss: 490.2913\n",
      "Epoch 146, Loss: 490.2599\n",
      "Epoch 147, Loss: 489.7056\n",
      "Epoch 148, Loss: 487.9749\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 149, Loss: 488.2398\n",
      "Epoch 150, Loss: 487.4978\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 151, Loss: 486.9217\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 152, Loss: 487.0756\n",
      "Epoch 153, Loss: 487.2169\n",
      "Epoch 154, Loss: 487.3817\n",
      "Epoch 155, Loss: 488.2832\n",
      "Epoch 156, Loss: 488.5877\n",
      "Epoch 157, Loss: 487.5934\n",
      "Epoch 158, Loss: 486.6754\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 159, Loss: 486.7376\n",
      "Epoch 160, Loss: 486.9359\n",
      "Epoch 161, Loss: 486.6607\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 162, Loss: 486.5510\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 163, Loss: 486.0073\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 164, Loss: 486.0242\n",
      "Epoch 165, Loss: 485.6287\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 166, Loss: 485.3064\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 167, Loss: 484.9691\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 168, Loss: 485.4514\n",
      "Epoch 169, Loss: 485.4276\n",
      "Epoch 170, Loss: 484.7634\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 171, Loss: 484.3854\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 172, Loss: 484.2103\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 173, Loss: 483.8139\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 174, Loss: 483.8090\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 175, Loss: 485.5280\n",
      "Epoch 176, Loss: 483.5118\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 177, Loss: 484.5389\n",
      "Epoch 178, Loss: 485.0407\n",
      "Epoch 179, Loss: 485.9226\n",
      "Epoch 180, Loss: 487.0457\n",
      "Epoch 181, Loss: 486.0308\n",
      "Epoch 182, Loss: 482.8000\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 183, Loss: 481.8013\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 184, Loss: 482.0472\n",
      "Epoch 185, Loss: 480.9141\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 186, Loss: 481.9870\n",
      "Epoch 187, Loss: 482.5125\n",
      "Epoch 188, Loss: 478.9892\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 189, Loss: 479.1579\n",
      "Epoch 190, Loss: 477.9758\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 191, Loss: 478.0252\n",
      "Epoch 192, Loss: 477.0582\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 193, Loss: 476.8107\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 194, Loss: 477.0296\n",
      "Epoch 195, Loss: 476.3571\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 196, Loss: 476.5161\n",
      "Epoch 197, Loss: 475.7973\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 198, Loss: 476.0387\n",
      "Epoch 199, Loss: 476.9786\n",
      "Epoch 200, Loss: 476.5839\n",
      "✅ Entrenamiento finalizado. Mejor pérdida: 475.7973\n",
      "💾 Embeddings guardados en vae_embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10337/137613486.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vae.load_state_dict(torch.load(\"vae_best_model.pt\"))\n"
     ]
    }
   ],
   "source": [
    "# Implementación de VAE en PyTorch\n",
    "\n",
    "# Carga de datos\n",
    "X = pd.read_csv(\"data/X_scaled_top20pct_genes.csv\", index_col=0)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Arquitectura VAE\n",
    "def build_linear_layers(sizes, activation=nn.ReLU):\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "        if i < len(sizes) - 2:\n",
    "            layers.append(activation())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=50, hidden_dims=[512, 256, 128]):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = build_linear_layers([input_dim] + hidden_dims, activation=nn.ReLU)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "        self.decoder = build_linear_layers(hidden_dims[::-1] + [input_dim], activation=nn.ReLU)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder_input(z)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = nn.L1Loss(reduction='sum')(recon_x, x)\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kld\n",
    "\n",
    "# Entrenamiento con EarlyStopping\n",
    "def train_vae(X_tensor, input_dim, latent_dim=50, hidden_dims=[512, 256, 128],\n",
    "              epochs=200, patience=15, model_path=\"vae_best_model.pt\"):\n",
    "    model = VAE(input_dim=input_dim, latent_dim=latent_dim, hidden_dims=hidden_dims).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in DataLoader(TensorDataset(X_tensor), batch_size=64, shuffle=True):\n",
    "            data = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = total_loss / len(X_tensor)\n",
    "        print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss - 1e-4:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"🔽 Nueva mejor pérdida. Modelo guardado.\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"🛑 Early stopping.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ Entrenamiento finalizado. Mejor pérdida: {best_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "# Entrenar el modelo\n",
    "input_dim = X.shape[1]\n",
    "X_tensor = X_tensor.to(device)\n",
    "vae = train_vae(X_tensor, input_dim=input_dim, latent_dim=50, epochs=200, patience=10)\n",
    "\n",
    "# Cargar mejor modelo entrenado\n",
    "vae.load_state_dict(torch.load(\"vae_best_model.pt\"))\n",
    "vae.eval()\n",
    "\n",
    "# Extraer embeddings\n",
    "with torch.no_grad():\n",
    "    mu, _ = vae.encode(X_tensor)\n",
    "embeddings = mu.cpu().numpy()\n",
    "pd.DataFrame(embeddings, index=X.index).to_csv(\"data/vae_embeddings_v2.csv\")\n",
    "print(\"💾 Embeddings guardados en vae_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef9cc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1504.8622\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 2, Loss: 865.3488\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 3, Loss: 670.1161\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 4, Loss: 629.5431\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 5, Loss: 610.9513\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 6, Loss: 605.6290\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 7, Loss: 603.5574\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 8, Loss: 600.7068\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 9, Loss: 599.3518\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 10, Loss: 590.0933\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 11, Loss: 587.4307\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 12, Loss: 585.3484\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 13, Loss: 583.3430\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 14, Loss: 580.9163\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 15, Loss: 580.1956\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 16, Loss: 578.6251\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 17, Loss: 576.8418\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 18, Loss: 575.2244\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 19, Loss: 573.5914\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 20, Loss: 572.4640\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 21, Loss: 572.7500\n",
      "Epoch 22, Loss: 571.9968\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 23, Loss: 569.3600\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 24, Loss: 567.9719\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 25, Loss: 564.8651\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 26, Loss: 564.0127\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 27, Loss: 568.7828\n",
      "Epoch 28, Loss: 563.3134\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 29, Loss: 557.3873\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 30, Loss: 556.4466\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 31, Loss: 555.3110\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 32, Loss: 552.2138\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 33, Loss: 551.8645\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 34, Loss: 554.2077\n",
      "Epoch 35, Loss: 555.8800\n",
      "Epoch 36, Loss: 550.5903\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 37, Loss: 550.7827\n",
      "Epoch 38, Loss: 549.7233\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 39, Loss: 549.9691\n",
      "Epoch 40, Loss: 547.5655\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 41, Loss: 548.4826\n",
      "Epoch 42, Loss: 547.9826\n",
      "Epoch 43, Loss: 547.7852\n",
      "Epoch 44, Loss: 551.6764\n",
      "Epoch 45, Loss: 549.2706\n",
      "Epoch 46, Loss: 545.7183\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 47, Loss: 544.2170\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 48, Loss: 543.1056\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 49, Loss: 541.3147\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 50, Loss: 540.6570\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 51, Loss: 538.9071\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 52, Loss: 537.8898\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 53, Loss: 534.9818\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 54, Loss: 539.4204\n",
      "Epoch 55, Loss: 529.3159\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 56, Loss: 527.6189\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 57, Loss: 521.1278\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 58, Loss: 519.6642\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 59, Loss: 517.2142\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 60, Loss: 516.9771\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 61, Loss: 515.9099\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 62, Loss: 514.1987\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 63, Loss: 512.3745\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 64, Loss: 511.3537\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 65, Loss: 511.7828\n",
      "Epoch 66, Loss: 513.7608\n",
      "Epoch 67, Loss: 515.2714\n",
      "Epoch 68, Loss: 510.9885\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 69, Loss: 511.3779\n",
      "Epoch 70, Loss: 510.1567\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 71, Loss: 507.6943\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 72, Loss: 509.0209\n",
      "Epoch 73, Loss: 511.5385\n",
      "Epoch 74, Loss: 508.1256\n",
      "Epoch 75, Loss: 506.8663\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 76, Loss: 506.0781\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 77, Loss: 505.1058\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 78, Loss: 504.4438\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 79, Loss: 504.7257\n",
      "Epoch 80, Loss: 502.5071\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 81, Loss: 501.6392\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 82, Loss: 501.1892\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 83, Loss: 500.5970\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 84, Loss: 500.0359\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 85, Loss: 499.2805\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 86, Loss: 499.4216\n",
      "Epoch 87, Loss: 498.9547\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 88, Loss: 499.3094\n",
      "Epoch 89, Loss: 498.6244\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 90, Loss: 498.2245\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 91, Loss: 500.7832\n",
      "Epoch 92, Loss: 501.5293\n",
      "Epoch 93, Loss: 498.9118\n",
      "Epoch 94, Loss: 498.8521\n",
      "Epoch 95, Loss: 499.2953\n",
      "Epoch 96, Loss: 500.2564\n",
      "Epoch 97, Loss: 502.1685\n",
      "Epoch 98, Loss: 500.3347\n",
      "Epoch 99, Loss: 499.4307\n",
      "Epoch 100, Loss: 497.3672\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 101, Loss: 498.4383\n",
      "Epoch 102, Loss: 497.7476\n",
      "Epoch 103, Loss: 496.6276\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 104, Loss: 498.3004\n",
      "Epoch 105, Loss: 498.8028\n",
      "Epoch 106, Loss: 501.7624\n",
      "Epoch 107, Loss: 498.5514\n",
      "Epoch 108, Loss: 498.5379\n",
      "Epoch 109, Loss: 497.5412\n",
      "Epoch 110, Loss: 496.2864\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 111, Loss: 496.7923\n",
      "Epoch 112, Loss: 496.7004\n",
      "Epoch 113, Loss: 498.7539\n",
      "Epoch 114, Loss: 496.3570\n",
      "Epoch 115, Loss: 495.8702\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 116, Loss: 494.2108\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 117, Loss: 493.8829\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 118, Loss: 493.6754\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 119, Loss: 493.2355\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 120, Loss: 493.4392\n",
      "Epoch 121, Loss: 492.5557\n",
      "🔽 Nueva mejor pérdida. Modelo guardado.\n",
      "Epoch 122, Loss: 493.0364\n",
      "Epoch 123, Loss: 492.8696\n",
      "Epoch 124, Loss: 493.2429\n",
      "Epoch 125, Loss: 493.5335\n",
      "Epoch 126, Loss: 494.2319\n",
      "Epoch 127, Loss: 494.5062\n",
      "Epoch 128, Loss: 495.8649\n",
      "Epoch 129, Loss: 496.2931\n",
      "Epoch 130, Loss: 495.5284\n",
      "Epoch 131, Loss: 494.4339\n",
      "🛑 Early stopping.\n",
      "✅ Entrenamiento finalizado. Mejor pérdida: 492.5557\n",
      "💾 Embeddings guardados en vae_embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10337/2356613977.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vae.load_state_dict(torch.load(\"vae_best_model_test.pt\"))\n"
     ]
    }
   ],
   "source": [
    "# Implementación de VAE en PyTorch para test\n",
    "\n",
    "# Carga de datos\n",
    "X = pd.read_csv(\"data/X_test_scaled_top20pct_genes.csv\", index_col=0)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Arquitectura VAE\n",
    "def build_linear_layers(sizes, activation=nn.ReLU):\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "        if i < len(sizes) - 2:\n",
    "            layers.append(activation())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=50, hidden_dims=[512, 256, 128]):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = build_linear_layers([input_dim] + hidden_dims, activation=nn.ReLU)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "        self.decoder = build_linear_layers(hidden_dims[::-1] + [input_dim], activation=nn.ReLU)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder_input(z)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = nn.L1Loss(reduction='sum')(recon_x, x)\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kld\n",
    "\n",
    "# Entrenamiento con EarlyStopping\n",
    "def train_vae(X_tensor, input_dim, latent_dim=50, hidden_dims=[512, 256, 128],\n",
    "              epochs=200, patience=15, model_path=\"vae_best_model_test.pt\"):\n",
    "    model = VAE(input_dim=input_dim, latent_dim=latent_dim, hidden_dims=hidden_dims).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in DataLoader(TensorDataset(X_tensor), batch_size=64, shuffle=True):\n",
    "            data = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = total_loss / len(X_tensor)\n",
    "        print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss - 1e-4:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"🔽 Nueva mejor pérdida. Modelo guardado.\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"🛑 Early stopping.\")\n",
    "                break\n",
    "\n",
    "    print(f\"✅ Entrenamiento finalizado. Mejor pérdida: {best_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "# Entrenar el modelo\n",
    "input_dim = X.shape[1]\n",
    "X_tensor = X_tensor.to(device)\n",
    "vae = train_vae(X_tensor, input_dim=input_dim, latent_dim=50, epochs=200, patience=10)\n",
    "\n",
    "# Cargar mejor modelo entrenado\n",
    "vae.load_state_dict(torch.load(\"vae_best_model_test.pt\"))\n",
    "vae.eval()\n",
    "\n",
    "# Extraer embeddings\n",
    "with torch.no_grad():\n",
    "    mu, _ = vae.encode(X_tensor)\n",
    "embeddings = mu.cpu().numpy()\n",
    "pd.DataFrame(embeddings, index=X.index).to_csv(\"data/vae_embeddings_test.csv\")\n",
    "print(\"💾 Embeddings guardados en vae_embeddings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
